{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import NoSuchElementException, ElementClickInterceptedException\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# Setup\n",
    "options = Options()\n",
    "options.add_argument(\"--headless\")\n",
    "options.add_argument(\"--disable-gpu\")\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "url = \"https://www.bbc.com/news/topics/cjxv13v27dyt\"\n",
    "driver.get(url)\n",
    "time.sleep(2)\n",
    "\n",
    "all_articles = []\n",
    "\n",
    "def extract_articles(soup):\n",
    "    articles = soup.find_all(\"div\", {\"data-testid\": \"liverpool-card\"})\n",
    "    results = []\n",
    "    for article in articles:\n",
    "        try:\n",
    "            link_tag = article.find(\"a\", {\"data-testid\": \"internal-link\"})\n",
    "            href = link_tag['href']\n",
    "            full_link = \"https://www.bbc.com\" + href\n",
    "\n",
    "            title = article.find(\"h2\", {\"data-testid\": \"card-headline\"}).get_text(strip=True)\n",
    "\n",
    "            region_tag = article.find(\"span\", {\"data-testid\": \"card-metadata-tag\"})\n",
    "            region = region_tag.get_text(strip=True) if region_tag else None\n",
    "\n",
    "            date_tag = article.find(\"span\", {\"data-testid\": \"card-metadata-lastupdated\"})\n",
    "            date = date_tag.get_text(strip=True) if date_tag else None\n",
    "\n",
    "            results.append({\n",
    "                \"title\": title,\n",
    "                \"link\": full_link,\n",
    "                \"region\": region,\n",
    "                \"date\": date\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(\"Error parsing article:\", e)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1...\n",
      "Scraping page 2...\n",
      "Scraping page 3...\n",
      "Scraping page 4...\n",
      "Scraping page 5...\n",
      "Scraping page 6...\n",
      "Scraping page 7...\n",
      "Scraping page 8...\n",
      "Scraping page 9...\n",
      "Scraping page 10...\n",
      "Scraping page 11...\n",
      "Scraping page 12...\n",
      "Scraping page 13...\n",
      "Scraping page 14...\n",
      "Scraping page 15...\n",
      "Scraping page 16...\n",
      "Scraping page 17...\n",
      "Scraping page 18...\n",
      "Scraping page 19...\n",
      "Scraping page 20...\n",
      "Scraping page 21...\n",
      "Scraping page 22...\n",
      "Scraping page 23...\n",
      "Scraping page 24...\n",
      "Scraping page 25...\n",
      "Scraping page 26...\n",
      "Scraping page 27...\n",
      "Scraping page 28...\n",
      "Scraping page 29...\n",
      "Scraping page 30...\n",
      "Scraping page 31...\n",
      "Reached last page.\n"
     ]
    }
   ],
   "source": [
    "# Pagination loop\n",
    "page = 1\n",
    "while True:\n",
    "    print(f\"Scraping page {page}...\")\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    all_articles.extend(extract_articles(soup))\n",
    "\n",
    "    try:\n",
    "        next_button = driver.find_element(\"xpath\", \"//button[@data-testid='pagination-next-button']\")\n",
    "        # Check if it's disabled\n",
    "        if next_button.get_attribute(\"disabled\"):\n",
    "            print(\"Reached last page.\")\n",
    "            break\n",
    "        next_button.click()\n",
    "        time.sleep(2)\n",
    "        page += 1\n",
    "    except (NoSuchElementException, ElementClickInterceptedException):\n",
    "        print(\"No more pages or click failed.\")\n",
    "        break\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(all_articles).drop_duplicates(subset=\"link\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(276, 4)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>region</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'Google AI presented my April Fools' story as ...</td>\n",
       "      <td>https://www.bbc.com/news/articles/cly12egqq5ko</td>\n",
       "      <td>Wales</td>\n",
       "      <td>3 Apr 2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Woman sentenced in case that sparked Springfie...</td>\n",
       "      <td>https://www.bbc.com/news/articles/cy890gpqw1po</td>\n",
       "      <td>US &amp; Canada</td>\n",
       "      <td>3 Dec 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Onion buys Alex Jones's Infowars at auction</td>\n",
       "      <td>https://www.bbc.com/news/articles/c30p1p0j0ddo</td>\n",
       "      <td>US &amp; Canada</td>\n",
       "      <td>14 Nov 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How US election fraud claims changed as Trump won</td>\n",
       "      <td>https://www.bbc.com/news/articles/cy9j8r8gg0do</td>\n",
       "      <td>US &amp; Canada</td>\n",
       "      <td>8 Nov 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Whirlwind of misinformation sows distrust ahea...</td>\n",
       "      <td>https://www.bbc.com/news/articles/czj7eex29r3o</td>\n",
       "      <td>Technology</td>\n",
       "      <td>3 Nov 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>What claims do you want BBC Reality Check to i...</td>\n",
       "      <td>https://www.bbc.com/news/uk-41928747</td>\n",
       "      <td>UK</td>\n",
       "      <td>17 Jan 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>Russia bans 'disrespect' of government</td>\n",
       "      <td>https://www.bbc.com/news/world-europe-47488267</td>\n",
       "      <td>Europe</td>\n",
       "      <td>7 Mar 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>QAnon: What's the truth behind a pro-Trump con...</td>\n",
       "      <td>https://www.bbc.com/news/blogs-trending-45040614</td>\n",
       "      <td>BBC Trending</td>\n",
       "      <td>2 Aug 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>BBC game challenges young people to spot \"fake...</td>\n",
       "      <td>https://www.bbc.com/news/school-report-43391188</td>\n",
       "      <td>Family &amp; Education</td>\n",
       "      <td>14 Mar 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>The (almost) complete history of 'fake news'</td>\n",
       "      <td>https://www.bbc.com/news/blogs-trending-42724320</td>\n",
       "      <td>BBC Trending</td>\n",
       "      <td>21 Jan 2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>276 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "0    'Google AI presented my April Fools' story as ...   \n",
       "1    Woman sentenced in case that sparked Springfie...   \n",
       "2      The Onion buys Alex Jones's Infowars at auction   \n",
       "3    How US election fraud claims changed as Trump won   \n",
       "4    Whirlwind of misinformation sows distrust ahea...   \n",
       "..                                                 ...   \n",
       "271  What claims do you want BBC Reality Check to i...   \n",
       "272             Russia bans 'disrespect' of government   \n",
       "273  QAnon: What's the truth behind a pro-Trump con...   \n",
       "274  BBC game challenges young people to spot \"fake...   \n",
       "275       The (almost) complete history of 'fake news'   \n",
       "\n",
       "                                                 link              region  \\\n",
       "0      https://www.bbc.com/news/articles/cly12egqq5ko               Wales   \n",
       "1      https://www.bbc.com/news/articles/cy890gpqw1po         US & Canada   \n",
       "2      https://www.bbc.com/news/articles/c30p1p0j0ddo         US & Canada   \n",
       "3      https://www.bbc.com/news/articles/cy9j8r8gg0do         US & Canada   \n",
       "4      https://www.bbc.com/news/articles/czj7eex29r3o          Technology   \n",
       "..                                                ...                 ...   \n",
       "271              https://www.bbc.com/news/uk-41928747                  UK   \n",
       "272    https://www.bbc.com/news/world-europe-47488267              Europe   \n",
       "273  https://www.bbc.com/news/blogs-trending-45040614        BBC Trending   \n",
       "274   https://www.bbc.com/news/school-report-43391188  Family & Education   \n",
       "275  https://www.bbc.com/news/blogs-trending-42724320        BBC Trending   \n",
       "\n",
       "            date  \n",
       "0     3 Apr 2025  \n",
       "1     3 Dec 2024  \n",
       "2    14 Nov 2024  \n",
       "3     8 Nov 2024  \n",
       "4     3 Nov 2024  \n",
       "..           ...  \n",
       "271  17 Jan 2020  \n",
       "272   7 Mar 2019  \n",
       "273   2 Aug 2018  \n",
       "274  14 Mar 2018  \n",
       "275  21 Jan 2018  \n",
       "\n",
       "[276 rows x 4 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm  # for progress bar\n",
    "\n",
    "def extract_article_text(url):\n",
    "    try:\n",
    "        headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        \n",
    "        text_blocks = soup.find_all(\"div\", {\"data-component\": \"text-block\"})\n",
    "        paragraphs = []\n",
    "        for block in text_blocks:\n",
    "            for p in block.find_all(\"p\"):\n",
    "                paragraphs.append(p.get_text(strip=True))\n",
    "        \n",
    "        return \" \".join(paragraphs)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to scrape {url}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Every year, journalist Ben Black publishes a playful fake story on his community news site Cwmbran Life for April Fools\\' Day. Since 2018 the 48-year-old has spun yarns including a Hollywood-style sign on a mountain to a nudist cold-water swimming club at a lake. In 2020, Mr Black published afake story claiming Cwmbran had been recognised by Guinness World Records for having the most roundabouts per square kilometre. Despite altering the wording of his article that afternoon, when he searched for it on 1 April he said he was \"shocked\" and \"worried\" to find the false information being used by Google\\'s AI tool and presented as real information. Google said it was looking into the matter. Mr Black decided to begin writing fake stories for April Fools\\' Day for \"a bit of fun\" and said his wife usually helped him come up with the ideas. The concept for his story in 2020 came from Cwmbran being a new town, where \"often linking houses with roundabouts is the easiest way to build\". \"I made up a number for the roundabouts per square kilometre and added a fake quote from a resident and clicked publish. \"It went down really well from memory, people laughed,\" he said. That afternoon, Mr Black marked the story as an April Fools\\' prank to clarify it was not fake news to his readers. However, the next day, he was \"annoyed\" to find it had been picked up by a larger national news website without his permission, and despite efforts to try and get the story removed, the story is still online. Mr Black said he had \"forgotten all about it\" until he searched for his previous stories on April Fools\\' Day this year. He said he was surprised to discover the Google AI tool and a learning to drive website using his article to claim Cwmbran reportedly had the world\\'s highest concentration of roundabouts. He said: \"It\\'s really scary that someone in Scotland could Google \\'roads in Wales\\' and come across a story that just isn\\'t true. \"It\\'s not a dangerous story, but it shows how fake news can easily spread even if it\\'s from a trusted news source. \"Even though I changed it all the same day, it shows down the line the internet can do it\\'s own thing. It\\'s just crazy.\" Mr Black said AI was becoming a growing threat to independent publishers, with many tools using their original content without permission and presenting it in different formats for others to benefit from. \"It is really frustrating because now no-one will visit our websites,\" he said. He also pointed out that larger news websites had struck deals with AI firms for collaboration, but said: \"There was no chance I\\'d be able to do that.\" Although Mr Black decided not to publish a fake story for April Fools\\' Day this year because he was \"too busy\", he said the experience had put him off and made him decide not to publish a fake story again.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_article_text('https://www.bbc.com/news/articles/cly12egqq5ko')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
